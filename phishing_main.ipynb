{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4fd39e",
   "metadata": {},
   "source": [
    "#### Introduction:\n",
    "Phishing is one of the most widespread and dangerious forms of cybercrime, where attackers deceive users into revealing personal information such as usernames, passwords, or financial details by masquerading as trustworthy entities. These attacks typically involve the use of fraudulent websites that mimic legitimate ones, and they continue to evolve in sophistication, making them harder to detect using traditional security filters.\n",
    "The goal of this project is to explore and analyze a phishing website dataset using statistical techniques and visual analysis. The dataset contains multiple features such as URL length, use of HTTPS, number of redirects, domain age, and whether the website uses popup windows or IP addresses. By understanding how these features differ between phishing and legitimate sites, we can uncover patterns that help in detecting phishing behavior.\n",
    "The project begins with data wrangling and cleaning to ensure data integrity. It then proceeds with descriptive statistics and visualizations to identify key trends. Using SciPy, we perform deeper statistical analysis such as t-tests, z-score outlier detection, chi-square independence testing, correlation analysis (Pearson and Spearman), and normality testing. These techniques allow us to quantify the significance of relationships and support data-driven decisions.\n",
    "\n",
    "Business Use Cases:\n",
    "Email Security Filters\n",
    "Phishing URL detection models can be integrated into email gateways to filter suspicious links before they reach users.\n",
    "Browser and Extension Security\n",
    "Real-time warning systems can be developed for browsers using models trained on features derived from this data.\n",
    "Enterprise Security Monitoring\n",
    "Cybersecurity teams can integrate phishing detection pipelines into SIEM (Security Information and Event Management) systems.\n",
    "Financial Services and Banking\n",
    "Banks can proactively flag suspicious sites impersonating their domains to protect customer credentials.\n",
    "Threat Intelligence Platforms\n",
    "Intelligence feeds can be enriched with pattern-based classification of URLs to detect new phishing campaigns early.\n",
    "Awareness and Training Tools\n",
    "Simulated phishing environments can be built using data insights to educate employees on phishing tactics.\n",
    "Government and Public Sector\n",
    "National cybersecurity initiatives can use these insights for public reporting systems and proactive protection strategies.\n",
    "\n",
    "This project offers a practical and educational approach to understanding phishing detection using a combination of statistics, visualization, and real-world cybersecurity concerns. It serves as a bridge between foundational data science techniques and applied cybersecurity solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b19b0",
   "metadata": {},
   "source": [
    "### ðŸ”¬ SciPy Lab: Phishing Website Detection Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1514f8",
   "metadata": {},
   "source": [
    "ðŸŽ¯ Objective:\n",
    "Use SciPy to perform statistical analysis on a phishing dataset and draw insights using real-world cybersecurity questions.\n",
    "Dataset: phishing_lab_dataset.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af9a17",
   "metadata": {},
   "source": [
    "### ðŸ§ª Use Case 1: Summary Statistics (Mean, Median, Mode)\n",
    "Q: Are phishing URLs typically longer than legitimate ones?\n",
    "Explanation:\n",
    "Mean gives the average URL length.\n",
    "Median shows the middle value (helps handle skewed data).\n",
    "Mode finds the most frequent URL length.\n",
    "Use all three to understand the central tendency of URL lengths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c32c0",
   "metadata": {},
   "source": [
    "### a. Load the csv file and find null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e38b9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " url_length            0\n",
      "has_ip_address        0\n",
      "https                 0\n",
      "domain_age          250\n",
      "has_at_symbol         0\n",
      "redirects             0\n",
      "prefix-suffix         0\n",
      "sfh                 150\n",
      "subdomains_count      0\n",
      "popup_window          0\n",
      "label                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# loading a DataFrame\n",
    "df = pd.read_csv('Dataset.csv')\n",
    "# Give the information on datasets\n",
    "\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6474186f",
   "metadata": {},
   "source": [
    "### b. Data Cleaning:\n",
    "- in missing shf place mode(most frequent value)\n",
    "- in domain age mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956fc9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url_length          0\n",
      "has_ip_address      0\n",
      "https               0\n",
      "domain_age          0\n",
      "has_at_symbol       0\n",
      "redirects           0\n",
      "prefix-suffix       0\n",
      "sfh                 0\n",
      "subdomains_count    0\n",
      "popup_window        0\n",
      "label               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate mode for 'sfh' and mean (rounded) for 'domain_age'\n",
    "sfh_mode = df['sfh'].mode()[0]\n",
    "domain_age_mean = round(df['domain_age'].mean(), 1)\n",
    "\n",
    "# Fill missing values\n",
    "df['sfh'] = df['sfh'].fillna(sfh_mode)\n",
    "df['domain_age'] = df['domain_age'].fillna(domain_age_mean)\n",
    "\n",
    "# Confirm no missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222dec3c",
   "metadata": {},
   "source": [
    "### c:\n",
    "- url_length put median value  in place of Long \n",
    "- in https place the mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79c8fec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A C E R\\AppData\\Local\\Temp\\ipykernel_9800\\349681544.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['url_length'].fillna(df['url_length'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fix url_length: replace 'long' with median\n",
    "df['url_length'] = pd.to_numeric(df['url_length'], errors='coerce')  # turns 'long' into NaN\n",
    "df['url_length'].fillna(df['url_length'].median(), inplace=True)\n",
    "\n",
    "# Fix https: replace anything not 0 or 1 with the most common (mode)\n",
    "df['https'] = df['https'].apply(lambda x: x if x in [0, 1] else df['https'].mode()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9616f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved as cleaned_file.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned file\n",
    "df.to_csv(\"cleaned_file.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned data saved as cleaned_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "999c87c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 79.8926 \n",
      "Median: 80.0 \n",
      "Mode: [80.]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "mean = df['url_length'].mean()\n",
    "median = df['url_length'].median()\n",
    "mode = stats.mode(df['url_length'], keepdims=True)\n",
    "print(f'Mean: {mean} \\nMedian: {median} \\nMode: {mode[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d1d5ea",
   "metadata": {},
   "source": [
    "### ðŸ§ª Use Case 2: Z-Test (Outlier Detection):\n",
    "Q: Are there any unusually long URLs that might be suspicious?\n",
    "Explanation:\n",
    "Z-score > 3 or < -3 indicates outliers.\n",
    "Helps spot extreme phishing attempts with oddly long URLs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac21cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total outliers found: 0\n",
      "Empty DataFrame\n",
      "Columns: [url_length, url_zscore]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Step 1: Calculate Z-scores for 'url_length'\n",
    "df['url_zscore'] = zscore(df['url_length'])\n",
    "\n",
    "# Step 2: Identify outliers (Z-score > 3 or < -3)\n",
    "outliers = df[df['url_zscore'].abs() > 3]\n",
    "\n",
    "# Print number of outliers and preview\n",
    "print(f\"Total outliers found: {len(outliers)}\")\n",
    "print(outliers[['url_length', 'url_zscore']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57195b5",
   "metadata": {},
   "source": [
    "### Use Case 3: T-Test (Comparing Two Groups)\n",
    "Q: Is there a significant difference in URL length between phishing and legitimate sites?\n",
    "\n",
    "Explanation:\n",
    "Null Hypothesis: The means are the same.\n",
    "If p < 0.05, the difference is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915602c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 11.380\n",
      "P-value: 0.0000\n",
      "âœ… The difference in URL length between phishing and legit websites is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Separate url_length based on label\n",
    "phishing = df[df['label'] == 1]['url_length']\n",
    "legit = df[df['label'] == 0]['url_length']\n",
    "\n",
    "# Perform t-test\n",
    "stat, p = ttest_ind(phishing, legit)\n",
    "\n",
    "# Print the result\n",
    "print(f\"T-statistic: {stat:.3f}\")\n",
    "print(f\"P-value: {p:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "if p < 0.05:\n",
    "    print(\"âœ… The difference in URL length between phishing and legit websites is statistically significant.\")\n",
    "else:\n",
    "    print(\"âŒ No significant difference in URL length between phishing and legit websites.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5025fb",
   "metadata": {},
   "source": [
    "### ðŸ§ª Use Case 4: Chi-Square Test (Categorical Association)\n",
    "Q: Is there a relationship between using HTTPS and phishing sites?\n",
    "\n",
    "Explanation:\n",
    "Tests if two categorical variables are independent.\n",
    "If p < 0.05, HTTPS usage and phishing are not independent â€” they may be related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13b999a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 220.926\n",
      "Degrees of freedom: 1\n",
      "P-value: 0.0\n",
      "âœ… There is a significant relationship between HTTPS usage and phishing/legit classification.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "\n",
    "# Create a contingency table\n",
    "contingency = pd.crosstab(df['https'], df['label'])\n",
    "\n",
    "# Run the chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "# Show results\n",
    "print(\"Chi-square statistic:\", round(chi2, 3))\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"P-value:\", round(p, 4))\n",
    "\n",
    "# Interpretation\n",
    "if p < 0.05:\n",
    "    print(\"âœ… There is a significant relationship between HTTPS usage and phishing/legit classification.\")\n",
    "else:\n",
    "    print(\"âŒ No significant relationship between HTTPS usage and phishing/legit classification.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e52d6",
   "metadata": {},
   "source": [
    "### ðŸ§ª Use Case 5: Correlation (Pearson and Spearman)\n",
    "Q: Do older domains tend to be more trustworthy (less phishing)?\n",
    "\n",
    "Explanation:\n",
    "Pearson: Measures linear relationship.\n",
    "Spearman: Measures monotonic (ranked) relationship.\n",
    "If correlations are negative, older domains may be less likely to be phishing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1cea661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Pearson correlation (linear): -0.022\n",
      "P-value (Pearson): 0.123\n",
      "ðŸ“ˆ Spearman correlation (monotonic): -0.021\n",
      "P-value (Spearman): 0.1389\n",
      "âŒ Pearson: No significant linear relationship.\n",
      "âŒ Spearman: No significant monotonic relationship.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Pearson: Measures linear correlation\n",
    "pearson_corr, p1 = pearsonr(df['domain_age'], df['label'])\n",
    "\n",
    "# Spearman: Measures monotonic relationship (doesn't require linearity)\n",
    "spearman_corr, p2 = spearmanr(df['domain_age'], df['label'])\n",
    "\n",
    "# Print results\n",
    "print(\"ðŸ“Š Pearson correlation (linear):\", round(pearson_corr, 3))\n",
    "print(\"P-value (Pearson):\", round(p1, 4))\n",
    "\n",
    "print(\"ðŸ“ˆ Spearman correlation (monotonic):\", round(spearman_corr, 3))\n",
    "print(\"P-value (Spearman):\", round(p2, 4))\n",
    "\n",
    "# Interpret results\n",
    "if p1 < 0.05:\n",
    "    print(\"âœ… Pearson: Significant linear relationship with domain_age.\")\n",
    "else:\n",
    "    print(\"âŒ Pearson: No significant linear relationship.\")\n",
    "\n",
    "if p2 < 0.05:\n",
    "    print(\"âœ… Spearman: Significant monotonic relationship with domain_age.\")\n",
    "else:\n",
    "    print(\"âŒ Spearman: No significant monotonic relationship.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cfdccf",
   "metadata": {},
   "source": [
    "### ðŸ§ª Use Case 6: Shapiro-Wilk Normality Test\n",
    "Q: Is the URL length data normally distributed?\n",
    "\n",
    "Important before running parametric tests (like t-test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2fbae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test statistic: 0.9570\n",
      "P-value: 0.0000\n",
      "Data is NOT normally distributed.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p = shapiro(df['url_length'])\n",
    "\n",
    "print(f\"Shapiro-Wilk test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {p:.4f}\")\n",
    "\n",
    "if p > 0.05:\n",
    "    print(\"Data is approximately normally distributed.\")\n",
    "else:\n",
    "    print(\"Data is NOT normally distributed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232acb0c",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broadwayenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
